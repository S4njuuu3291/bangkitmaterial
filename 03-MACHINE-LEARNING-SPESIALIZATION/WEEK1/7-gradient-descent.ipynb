{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent: Overview\n",
    "\n",
    "Selamat datang kembali! Pada video sebelumnya, kita melihat visualisasi dari fungsi biaya $ j $ dan bagaimana Anda bisa mencoba berbagai pilihan parameter $ w $ dan $ b $ untuk melihat nilai biaya yang dihasilkan. \n",
    "\n",
    "Namun, kita ingin menemukan cara yang lebih sistematis untuk menemukan nilai $ w $ dan $ b $ yang menghasilkan biaya terkecil, $ j(w, b) $. \n",
    "\n",
    "Ternyata, ada algoritma yang disebut **gradient descent** yang dapat Anda gunakan untuk itu. Gradient descent digunakan di berbagai tempat dalam pembelajaran mesin, tidak hanya untuk regresi linier, tetapi juga untuk pelatihan beberapa model jaringan saraf yang paling canggih (deep learning).\n",
    "\n",
    "## Tujuan Gradient Descent\n",
    "\n",
    "Tujuan dari **gradient descent** adalah untuk meminimalkan fungsi biaya $ j(w, b) $. Misalnya, dalam regresi linier, kita meminimalkan fungsi biaya yang merupakan kesalahan kuadrat antara prediksi model dan nilai aktual.\n",
    "\n",
    "### Apa Itu Gradient Descent?\n",
    "\n",
    "Gradient descent adalah algoritma yang digunakan untuk meminimalkan fungsi $ j(w, b) $, dengan mengubah nilai parameter $ w $ dan $ b $ sedikit demi sedikit pada setiap iterasi untuk mencoba mencapai nilai terkecil dari fungsi biaya.\n",
    "\n",
    "1. **Tebakan Awal**: Mulai dengan tebakan awal untuk parameter $ w $ dan $ b $, misalnya $ w = 0 $ dan $ b = 0 $.\n",
    "2. **Langkah-Langkah**: Perbarui parameter secara iteratif untuk mendekati nilai yang meminimalkan fungsi biaya.\n",
    "3. **Tujuan Akhir**: Mencapai nilai terkecil dari $ j(w, b) $, yang disebut **minimum lokal**.\n",
    "\n",
    "---\n",
    "\n",
    "## Visualisasi Fungsi Biaya\n",
    "\n",
    "Fungsi biaya $ j(w, b) $ bisa digambarkan dalam bentuk grafik permukaan 3D. Bayangkan permukaan ini seperti sebuah **bukit** dan **lembah**.\n",
    "\n",
    "![](https://example.com/graph.png)\n",
    "\n",
    "- **Sumbu x**: Parameter $ w $\n",
    "- **Sumbu y**: Parameter $ b $\n",
    "- **Sumbu z**: Fungsi biaya $ j(w, b) $\n",
    "\n",
    "### Menuruni Bukit\n",
    "\n",
    "Dalam gradient descent, Anda berdiri di atas bukit dan ingin mencapai dasar lembah. Arah yang paling terjal adalah arah penurunan tercepat dari fungsi biaya. Inilah yang disebut dengan **gradien**.\n",
    "\n",
    "- **Langkah pertama**: Berdiri di titik tinggi di atas bukit.\n",
    "- **Langkah kedua**: Lihat sekeliling dan tentukan arah terjal untuk bergerak turun secepat mungkin.\n",
    "\n",
    "Formula matematis untuk langkah gradient descent adalah sebagai berikut:\n",
    "\n",
    "$$\n",
    "w := w - \\alpha \\frac{\\partial j(w, b)}{\\partial w}\n",
    "$$\n",
    "$$\n",
    "b := b - \\alpha \\frac{\\partial j(w, b)}{\\partial b}\n",
    "$$\n",
    "\n",
    "Di mana $ \\alpha $ adalah **learning rate** yang mengontrol besar langkah per iterasi.\n",
    "\n",
    "---\n",
    "\n",
    "## Minimum Lokal dan Global\n",
    "\n",
    "Terkadang, fungsi $ j(w, b) $ memiliki lebih dari satu lembah. Jika gradient descent dimulai dari titik yang berbeda, kita mungkin sampai di minimum lokal yang berbeda, bukan minimum global.\n",
    "\n",
    "1. **Minimum Lokal**: Titik di mana fungsi biaya lebih rendah dibandingkan titik di sekitarnya, tetapi tidak pasti yang terendah di seluruh ruang parameter.\n",
    "2. **Minimum Global**: Titik dengan nilai biaya paling rendah di seluruh ruang parameter.\n",
    "\n",
    "Jika kita memulai di titik berbeda, kita mungkin mendapatkan hasil yang berbeda:\n",
    "\n",
    "- **Titik awal A**: Sampai di minimum lokal pertama.\n",
    "- **Titik awal B**: Sampai di minimum lokal kedua.\n",
    "\n",
    "---\n",
    "\n",
    "## Kesimpulan\n",
    "\n",
    "Gradient descent adalah metode powerful untuk menemukan nilai optimal dari parameter model. Dengan memahami konsep ini, Anda dapat mengaplikasikannya pada berbagai model pembelajaran mesin lainnya, seperti jaringan saraf dalam (deep learning).\n",
    "\n",
    "Pada video berikutnya, kita akan mengimplementasikan algoritma ini secara matematis dan mulai mengoptimalkan fungsi biaya dalam kode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
