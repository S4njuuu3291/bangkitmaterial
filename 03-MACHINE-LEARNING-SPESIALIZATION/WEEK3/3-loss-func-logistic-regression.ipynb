{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi Logistik: Fungsi Biaya dan Fungsi Kehilangan\n",
    "\n",
    "Pada video kali ini, kita akan membahas mengapa **fungsi biaya kesalahan kuadrat** tidak ideal untuk **regresi logistik** dan memperkenalkan **fungsi kehilangan** baru yang lebih cocok untuk regresi logistik. Kami juga akan membahas bagaimana hal ini menghasilkan proses **gradien descent** yang lebih andal untuk menemukan parameter terbaik bagi model.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Pendahuluan ke Fungsi Biaya**\n",
    "\n",
    "**Fungsi biaya** mengukur seberapa baik sekumpulan parameter cocok dengan data pelatihan. Tujuannya adalah untuk menemukan parameter yang meminimalkan biaya ini, sehingga menghasilkan prediksi yang lebih baik.\n",
    "\n",
    "Untuk **regresi logistik**, fungsi biaya membantu kita memilih parameter terbaik (yang dilambangkan dengan **w** dan **b**) berdasarkan set pelatihan.\n",
    "\n",
    "- **Contoh Set Pelatihan**: Misalnya kita memiliki set pelatihan di mana setiap baris mewakili pasien yang mengunjungi dokter, dan setiap pasien memiliki berbagai fitur seperti ukuran tumor, usia, dll.\n",
    "- Misalkan **m** adalah jumlah contoh pelatihan, dan **n** adalah jumlah fitur (seperti **X₁, X₂, ..., Xₙ**).\n",
    "- Variabel target **y** bersifat biner, artinya hanya mengambil nilai 0 atau 1, yang mewakili tugas klasifikasi.\n",
    "\n",
    "### **Model Regresi Logistik**\n",
    "\n",
    "Model regresi logistik didefinisikan sebagai:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{1 + e^{-(w \\cdot x + b)}}\n",
    "$$\n",
    "\n",
    "Di sini:\n",
    "- **w** adalah bobot (weights).\n",
    "- **x** adalah vektor fitur input.\n",
    "- **b** adalah bias.\n",
    "- Model menghasilkan output yang berupa probabilitas antara 0 dan 1.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Fungsi Biaya untuk Regresi Linier**\n",
    "\n",
    "Pada regresi linier, fungsi biaya yang umum digunakan adalah **fungsi biaya kesalahan kuadrat (squared error cost function)**. Fungsi biaya ini digunakan untuk mengukur selisih antara prediksi model dan nilai target yang sesungguhnya.\n",
    "\n",
    "Namun, jika kita menggunakan fungsi biaya ini untuk regresi logistik, hasilnya menjadi tidak ideal.\n",
    "\n",
    "### **Mengapa Fungsi Biaya Kuadrat Tidak Ideal untuk Regresi Logistik?**\n",
    "\n",
    "Pada regresi logistik, prediksi model berupa probabilitas yang selalu berada di antara 0 dan 1. Ketika kita menggunakan **fungsi biaya kesalahan kuadrat** dengan fungsi sigmoid, grafik dari biaya ini menjadi **non-konveks** (tidak berbentuk cekung).\n",
    "\n",
    "- **Masalahnya**: Fungsi biaya non-konveks memiliki banyak **minimum lokal**, yang berarti **gradien descent** bisa terjebak di titik yang bukan minimum global, yang akhirnya menyebabkan model tidak dapat menemukan parameter yang optimal.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Memperkenalkan Fungsi Kehilangan (Loss Function) Baru**\n",
    "\n",
    "Untuk mengatasi masalah ini, kita memperkenalkan **fungsi kehilangan** baru yang akan membuat fungsi biaya menjadi **konveks** (berbentuk cekung), memungkinkan **gradien descent** untuk selalu mencapai **minimum global**.\n",
    "\n",
    "### **Definisi Fungsi Kehilangan untuk Regresi Logistik**\n",
    "\n",
    "Fungsi kehilangan di sini dihitung berdasarkan perbedaan antara prediksi model dan label target. Fungsi kehilangan untuk satu contoh pelatihan dapat dituliskan sebagai:\n",
    "\n",
    "- Jika label **y = 1**, maka kehilangan adalah **-log(f(x))**\n",
    "- Jika label **y = 0**, maka kehilangan adalah **-log(1 - f(x))**\n",
    "\n",
    "Di mana:\n",
    "- **f(x)** adalah output dari model regresi logistik (probabilitas yang diprediksi).\n",
    "- **y** adalah label target (0 atau 1).\n",
    "\n",
    "Fungsi kehilangan ini mengukur seberapa besar kesalahan prediksi model untuk setiap contoh pelatihan.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Mengapa Fungsi Kehilangan Ini Logis?**\n",
    "\n",
    "### **Kasus 1: y = 1**\n",
    "\n",
    "Ketika **y = 1** (misalnya tumor ganas), kita berharap model memprediksi probabilitas mendekati 1. Grafik dari **log(f(x))** akan terlihat seperti ini:\n",
    "\n",
    "- Jika **f(x)** mendekati 1, **log(f(x))** mendekati 0, yang berarti kehilangan (loss) kecil, artinya model sudah cukup akurat.\n",
    "- Sebaliknya, jika **f(x)** mendekati 0, maka **log(f(x))** menjadi sangat besar negatif, yang menghasilkan **loss besar**. Ini berarti model salah besar dalam memprediksi bahwa tumor tidak ganas padahal sebenarnya ganas.\n",
    "\n",
    "### **Kasus 2: y = 0**\n",
    "\n",
    "Ketika **y = 0** (misalnya tumor jinak), kita berharap model memprediksi probabilitas mendekati 0. Grafik dari **log(1 - f(x))** akan terlihat seperti ini:\n",
    "\n",
    "- Jika **f(x)** mendekati 0, maka **log(1 - f(x))** mendekati 0, artinya model memprediksi dengan sangat tepat.\n",
    "- Namun, jika **f(x)** mendekati 1, maka **log(1 - f(x))** menjadi sangat besar negatif, yang menghasilkan **loss yang sangat besar**. Ini berarti model membuat prediksi yang sangat salah (misalnya tumor yang seharusnya jinak diprediksi sangat ganas).\n",
    "\n",
    "### **Visualisasi Fungsi Kehilangan**\n",
    "\n",
    "- Jika prediksi mendekati label yang benar, loss sangat kecil.\n",
    "- Jika prediksi jauh dari label yang benar, loss menjadi sangat besar.\n",
    "- Fungsi kehilangan ini mengarahkan model untuk meminimalkan perbedaan antara probabilitas yang diprediksi dengan label yang sesungguhnya, sehingga meningkatkan akurasi prediksi.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Fungsi Biaya untuk Semua Contoh Pelatihan**\n",
    "\n",
    "Fungsi biaya untuk seluruh set pelatihan dihitung dengan menjumlahkan fungsi kehilangan untuk setiap contoh pelatihan. Fungsi biaya total dapat dituliskan sebagai:\n",
    "\n",
    "$$\n",
    "J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} L(f(x^{(i)}), y^{(i)})\n",
    "$$\n",
    "\n",
    "Di mana:\n",
    "- **m** adalah jumlah total contoh pelatihan.\n",
    "- **L(f(x^{(i)}), y^{(i)})** adalah fungsi kehilangan untuk contoh pelatihan ke-i.\n",
    "\n",
    "Fungsi biaya ini adalah rata-rata dari kehilangan untuk seluruh contoh pelatihan. Dengan meminimalkan fungsi biaya ini, kita dapat menemukan parameter **w** dan **b** yang terbaik untuk model.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **Gradien Descent untuk Regresi Logistik**\n",
    "\n",
    "Dengan fungsi kehilangan yang baru ini, fungsi biaya menjadi **konveks**. Hal ini memungkinkan kita menggunakan **gradien descent** untuk menemukan parameter **w** dan **b** yang meminimalkan fungsi biaya secara lebih efisien.\n",
    "\n",
    "- Fungsi biaya konveks memiliki **satu minimum global**, yang membuat gradien descent lebih andal dalam mencari parameter optimal.\n",
    "- Sebaliknya, fungsi biaya non-konveks dapat memiliki banyak minimum lokal, yang bisa menjebak gradien descent di titik yang salah.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. **Kesimpulan**\n",
    "\n",
    "Pada video ini, kita telah belajar mengapa **fungsi biaya kesalahan kuadrat** tidak bekerja dengan baik untuk **regresi logistik** dan mengapa kita perlu **fungsi kehilangan baru** yang berbasis **logaritma**. Dengan pendekatan ini, fungsi biaya menjadi **konveks**, memungkinkan **gradien descent** untuk mencapai **minimum global** dan menemukan parameter yang optimal untuk model regresi logistik.\n",
    "\n",
    "Pada video selanjutnya, kita akan melihat lebih dalam bagaimana fungsi biaya ini diterapkan dan bagaimana kita dapat menggunakan **gradien descent** untuk melatih model regresi logistik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
