{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi Logistik: Penyederhanaan Fungsi Kehilangan dan Fungsi Biaya\n",
    "\n",
    "Dalam video kali ini, kita akan mempelajari cara menulis ulang **fungsi kehilangan** dan **fungsi biaya** untuk regresi logistik dengan cara yang lebih sederhana. Tujuannya adalah untuk membuat implementasi lebih mudah saat kita mulai menggunakan **gradien descent** untuk menyesuaikan parameter model regresi logistik.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Mengingat Fungsi Kehilangan untuk Regresi Logistik**\n",
    "\n",
    "Sebagai pengingat, fungsi kehilangan yang kita definisikan sebelumnya untuk regresi logistik adalah sebagai berikut:\n",
    "\n",
    "$$\n",
    "L(f(x), y) = -y \\cdot \\log(f(x)) - (1 - y) \\cdot \\log(1 - f(x))\n",
    "$$\n",
    "\n",
    "Di mana:\n",
    "- **f(x)** adalah prediksi model.\n",
    "- **y** adalah label target, yang bisa bernilai 0 atau 1.\n",
    "\n",
    "Karena **y** hanya dapat bernilai 0 atau 1, kita dapat menyederhanakan rumus ini menjadi bentuk yang lebih ringkas.\n",
    "\n",
    "### **Fungsi Kehilangan yang Disederhanakan**\n",
    "\n",
    "Fungsi kehilangan yang lebih sederhana adalah:\n",
    "\n",
    "$$\n",
    "L(f(x), y) = -y \\cdot \\log(f(x)) - (1 - y) \\cdot \\log(1 - f(x))\n",
    "$$\n",
    "\n",
    "Sekarang mari kita lihat mengapa rumus ini ekuivalen dengan rumus yang lebih kompleks yang kita gunakan sebelumnya.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Mengapa Penyederhanaan Ini Bekerja**\n",
    "\n",
    "### **Kasus 1: y = 1**\n",
    "Jika **y = 1**, maka kita memiliki:\n",
    "- \\( y = 1 \\) dan \\( 1 - y = 0 \\).\n",
    "- Dengan demikian, rumusnya menjadi:\n",
    "  \n",
    "  $$\n",
    "  L(f(x), 1) = -1 \\cdot \\log(f(x)) - 0 \\cdot \\log(1 - f(x)) = -\\log(f(x))\n",
    "  $$\n",
    "\n",
    "Ini adalah **fungsi kehilangan** yang sesuai dengan **y = 1** yang kita definisikan sebelumnya.\n",
    "\n",
    "### **Kasus 2: y = 0**\n",
    "Jika **y = 0**, maka kita memiliki:\n",
    "- \\( y = 0 \\) dan \\( 1 - y = 1 \\).\n",
    "- Dengan demikian, rumusnya menjadi:\n",
    "  \n",
    "  $$\n",
    "  L(f(x), 0) = 0 \\cdot \\log(f(x)) - 1 \\cdot \\log(1 - f(x)) = -\\log(1 - f(x))\n",
    "  $$\n",
    "\n",
    "Ini adalah **fungsi kehilangan** yang sesuai dengan **y = 0** yang kita definisikan sebelumnya.\n",
    "\n",
    "### **Kesimpulan**\n",
    "Dengan demikian, fungsi kehilangan yang lebih sederhana ini:\n",
    "\n",
    "$$\n",
    "L(f(x), y) = -y \\cdot \\log(f(x)) - (1 - y) \\cdot \\log(1 - f(x))\n",
    "$$\n",
    "\n",
    "adalah ekuivalen dengan rumus yang lebih kompleks yang kita gunakan sebelumnya, tetapi lebih sederhana dan lebih efisien untuk implementasi.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Fungsi Biaya untuk Regresi Logistik**\n",
    "\n",
    "Sekarang kita akan menulis **fungsi biaya** untuk regresi logistik menggunakan fungsi kehilangan yang telah disederhanakan.\n",
    "\n",
    "### **Fungsi Biaya**\n",
    "\n",
    "Fungsi biaya untuk regresi logistik adalah rata-rata dari fungsi kehilangan untuk seluruh set pelatihan yang terdiri dari **m** contoh. Secara matematis, ini dapat dituliskan sebagai:\n",
    "\n",
    "$$\n",
    "J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} L(f(x^{(i)}), y^{(i)})\n",
    "$$\n",
    "\n",
    "Di mana:\n",
    "- **m** adalah jumlah total contoh pelatihan.\n",
    "- **L(f(x^{(i)}), y^{(i)})** adalah fungsi kehilangan untuk contoh pelatihan ke-i.\n",
    "\n",
    "Jika kita menggantikan fungsi kehilangan yang disederhanakan ke dalam rumus ini, kita mendapatkan:\n",
    "\n",
    "$$\n",
    "J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} \\left( -y^{(i)} \\cdot \\log(f(x^{(i)})) - (1 - y^{(i)}) \\cdot \\log(1 - f(x^{(i)})) \\right)\n",
    "$$\n",
    "\n",
    "Jika kita menyatukan konstanta negatif di luar, kita dapat menulisnya sebagai:\n",
    "\n",
    "$$\n",
    "J(w, b) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left( y^{(i)} \\cdot \\log(f(x^{(i)})) + (1 - y^{(i)}) \\cdot \\log(1 - f(x^{(i)})) \\right)\n",
    "$$\n",
    "\n",
    "Inilah **fungsi biaya** yang paling umum digunakan untuk melatih model regresi logistik. Fungsi biaya ini **konveks**, yang berarti kita dapat menggunakan **gradien descent** untuk menemukan parameter optimal **w** dan **b**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Mengapa Memilih Fungsi Biaya Ini?**\n",
    "\n",
    "Mungkin Anda bertanya-tanya, mengapa kita memilih fungsi biaya ini ketika ada banyak fungsi biaya lain yang bisa digunakan? Meskipun kita tidak akan membahasnya secara mendalam dalam kursus ini, fungsi biaya ini sebenarnya berasal dari **maximum likelihood estimation (MLE)**, yaitu pendekatan statistik yang digunakan untuk mengestimasi parameter model.\n",
    "\n",
    "Fungsi biaya ini memiliki sifat penting, yaitu **konveks**, yang memungkinkan kita menggunakan gradien descent untuk dengan aman menemukan **minimum global** tanpa terjebak di **minimum lokal**.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Lab Opsional dan Implementasi Kode**\n",
    "\n",
    "Di lab opsional yang akan datang, Anda akan melihat bagaimana **fungsi biaya regresi logistik** diimplementasikan dalam kode. Saya sangat menyarankan Anda untuk memeriksanya, karena ini akan membantu Anda memahami penerapan konsep ini secara praktis.\n",
    "\n",
    "Lab ini juga akan menunjukkan bagaimana **dua pilihan parameter yang berbeda** akan menghasilkan perhitungan biaya yang berbeda. Anda akan dapat melihat bahwa **batas keputusan biru** yang lebih baik memiliki biaya lebih rendah dibandingkan dengan **batas keputusan magenta** yang lebih buruk.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **Persiapan untuk Gradient Descent**\n",
    "\n",
    "Dengan fungsi biaya yang telah disederhanakan ini, kita siap untuk melanjutkan dan mengaplikasikan **gradien descent** pada **regresi logistik**. Pada video selanjutnya, kita akan melihat bagaimana cara menggunakan **gradien descent** untuk melatih model regresi logistik secara efektif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
