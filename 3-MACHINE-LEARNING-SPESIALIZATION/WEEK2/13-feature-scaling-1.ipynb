{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Gradient Descent untuk Regresi Linear Berganda dengan Vektorisasi**\n",
    "\n",
    "## Pendahuluan\n",
    "Anda telah belajar tentang gradient descent, regresi linear berganda, dan vektorisasi. Sekarang, kita akan menerapkan gradient descent dengan vektorisasi untuk regresi linear berganda.\n",
    "\n",
    "### Penulisan Model dalam Notasi Vektor\n",
    "Kita punya parameter \\( w_1, w_2, ..., w_n \\) dan \\( b \\). Kita akan mengumpulkan semua \\( w \\) ke dalam vektor \\( w \\), sehingga model dapat ditulis sebagai:\n",
    "$$[ f_{w,b}(x) = w \\cdot x + b ]$$\n",
    "Kita juga dapat menulis fungsi biaya sebagai \\( J(w, b) \\).\n",
    "\n",
    "### Update Parameter dalam Gradient Descent\n",
    "Setiap parameter \\( w_j \\) di-update menggunakan aturan:\n",
    "$$[ w_j = w_j - \\alpha \\frac{\\partial J}{\\partial w_j} ]$$\n",
    "di mana \\( \\alpha \\) adalah learning rate. Gradient descent untuk banyak fitur serupa dengan kasus satu fitur, hanya saja \\( w \\) dan \\( x \\) sekarang berupa vektor.\n",
    "\n",
    "### Normal Equation\n",
    "Alternatif dari gradient descent adalah **normal equation**, metode yang menyelesaikan \\( w \\) dan \\( b \\) tanpa iterasi. Namun, metode ini lebih lambat jika jumlah fitur sangat besar dan tidak digunakan pada algoritma pembelajaran lain seperti regresi logistik.\n",
    "\n",
    "### Implementasi di Python\n",
    "Anda akan melihat cara mendefinisikan model regresi berganda, menghitung prediksi \\( f(x) \\), dan menerapkan gradient descent menggunakan pustaka NumPy.\n",
    "\n",
    "---\n",
    "\n",
    "# **Scaling Fitur untuk Gradient Descent yang Lebih Cepat**\n",
    "\n",
    "## Pentingnya Scaling Fitur\n",
    "Fitur dengan rentang nilai yang besar dapat menyebabkan gradient descent bekerja lebih lambat. Contoh, jika kita memprediksi harga rumah berdasarkan ukuran rumah (x1) dan jumlah kamar tidur (x2):\n",
    "- \\( x_1 \\) berkisar dari 300 hingga 2000 kaki persegi.\n",
    "- \\( x_2 \\) berkisar dari 0 hingga 5 kamar tidur.\n",
    "\n",
    "Jika gradient descent dijalankan tanpa scaling, model bisa lambat untuk mencapai minimum global karena fitur-fitur ini memiliki rentang nilai yang berbeda.\n",
    "\n",
    "## Contoh Skala Fitur\n",
    "Misalkan:\n",
    "- \\( w_1 = 0.1 \\) dan \\( w_2 = 50 \\) akan menghasilkan prediksi yang masuk akal. \n",
    "- Sebaliknya, perbedaan besar antara \\( w_1 \\) dan \\( w_2 \\) bisa menyebabkan perhitungan model melambat.\n",
    "\n",
    "### Efek Scaling pada Gradient Descent\n",
    "Dalam plot kontur, tanpa scaling, gradient descent mungkin memantul bolak-balik sebelum mencapai minimum. Dengan scaling, fitur-fitur disesuaikan agar berada dalam rentang yang sama (misalnya 0 hingga 1). Ini mempercepat proses gradient descent.\n",
    "\n",
    "### Ringkasan\n",
    "Scaling fitur membantu gradient descent bekerja lebih cepat dengan mengurangi perbedaan besar antara rentang nilai fitur-fitur. Dengan scaling, gradient descent dapat menemukan jalur lebih langsung menuju minimum global.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metode untuk **Feature Scaling**:\n",
    "\n",
    "1. **Scaling Sederhana:**\n",
    "   - Untuk fitur yang memiliki rentang nilai yang sangat berbeda (misalnya, `x1` memiliki rentang dari 3 hingga 2000), kamu bisa melakukan scaling dengan membagi setiap nilai dengan nilai maksimum dalam rentang tersebut.\n",
    "   - Sebagai contoh, membagi `x1` dengan 2000 akan menskalakan nilainya antara 0,15 hingga 1. Demikian juga, `x2` dapat diskalakan dengan membaginya dengan nilai maksimumnya (5), sehingga skalanya akan berada antara 0 hingga 1.\n",
    "\n",
    "2. **Mean Normalization (Normalisasi Rata-rata):**\n",
    "   - Metode lain adalah **mean normalization**, di mana kamu mengambil nilai fitur asli dan menskalakannya agar fitur tersebut terpusat di sekitar nol, sehingga memiliki nilai negatif dan positif.\n",
    "   - Sebagai contoh, jika `x1` memiliki rentang dari 300 hingga 2000, kamu bisa menghitung rata-rata (atau disebut juga **mean**) dari `x1`, yang kita sebut sebagai `Mu_1`. Misalnya, rata-rata `x1` adalah 600. Kamu bisa mengambil setiap `x1`, mengurangi `Mu_1`, lalu membaginya dengan rentang 2000 dikurangi 300. Hasilnya, nilai `x1` yang sudah dinormalisasi akan berkisar dari -0,18 hingga 0,82.\n",
    "   - Untuk fitur `x2`, jika memiliki rentang dari 0 hingga 5, kamu bisa menghitung rata-rata `Mu_2`, lalu mengambil setiap `x2`, menguranginya dengan `Mu_2`, dan membaginya dengan 5 - 0. Hasilnya, nilai `x2` yang sudah dinormalisasi akan berkisar dari -0,46 hingga 0,54.\n",
    "\n",
    "3. **Z-Score Normalization (Normalisasi Z-Score):**\n",
    "   - Metode lain adalah **Z-score normalization**, di mana kamu menghitung rata-rata (`Mu`) dan standar deviasi (`Sigma`) untuk setiap fitur.\n",
    "   - Sebagai contoh, jika fitur `x1` memiliki standar deviasi 450 dan rata-rata 600, maka untuk melakukan **Z-score normalization**, ambil setiap `x1`, kurangi dengan `Mu_1`, lalu bagi dengan `Sigma_1`. Hasilnya, nilai `x1` yang sudah dinormalisasi dengan Z-score bisa berkisar dari -0,67 hingga 3,1.\n",
    "   - Demikian juga, untuk fitur `x2`, jika standar deviasinya adalah 1,4 dan rata-ratanya 2,3, kamu bisa menghitung `x2 - Mu_2` dan membaginya dengan `Sigma_2`. Dalam kasus ini, hasilnya berkisar antara -1,6 hingga 1,9.\n",
    "\n",
    "### Panduan Umum:\n",
    "   - Sebagai aturan umum, ketika melakukan feature scaling, kamu mungkin ingin menskalakan fitur-fitur agar rentangnya berada sekitar -1 hingga 1 untuk setiap fitur `x`. Namun, rentang ini tidak harus selalu tepat. Jika rentang fiturnya antara -3 hingga 3, atau -0,3 hingga 0,3, itu masih bisa diterima.\n",
    "   - Jika fitur `x3` memiliki rentang yang jauh berbeda, misalnya dari -100 hingga 100, maka sebaiknya fitur ini diskalakan agar rentangnya lebih mendekati -1 hingga 1.\n",
    "   - Jika fitur `x4` memiliki nilai yang sangat kecil, seperti antara -0,001 dan 0,001, maka disarankan juga untuk melakukan scaling.\n",
    "   - Contoh lainnya, jika fitur `x5` (misalnya suhu tubuh pasien di rumah sakit) memiliki rentang dari 98,6 hingga 105 derajat Fahrenheit, maka nilai ini cukup besar dibandingkan fitur yang sudah diskalakan lainnya. Melakukan scaling dalam kasus ini bisa mempercepat algoritma gradient descent.\n",
    "\n",
    "### Kesimpulan:\n",
    "   - Hampir tidak ada kerugian dalam melakukan **feature scaling**. Jika ragu, lakukan saja scaling untuk memastikan model berjalan dengan baik.\n",
    "   - Scaling fitur dapat membantu mempercepat algoritma seperti **gradient descent**.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
