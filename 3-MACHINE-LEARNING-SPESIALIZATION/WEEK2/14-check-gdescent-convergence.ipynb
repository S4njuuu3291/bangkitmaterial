{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cara Mengetahui Apakah Gradient Descent Sudah Konvergen\n",
    "\n",
    "Saat menjalankan **gradient descent**, bagaimana kita tahu jika prosesnya sudah konvergen, atau mendekati minimum global dari fungsi biaya (**cost function**)?\n",
    "\n",
    "Dengan memahami bagaimana implementasi **gradient descent** yang baik, kita nantinya bisa lebih mudah memilih **learning rate** yang tepat. Mari kita bahas.\n",
    "\n",
    "#### Aturan Gradient Descent\n",
    "Sebagai pengingat, berikut adalah **aturan gradient descent**. Salah satu elemen penting dalam proses ini adalah memilih **learning rate** **α (Alpha)**. Ini yang sering saya lakukan untuk memastikan **gradient descent** bekerja dengan baik.\n",
    "\n",
    "Tugas utama **gradient descent** adalah mencari parameter **w** dan **b** yang meminimalkan fungsi biaya **J**. Biasanya, saya memplot **J**, yang dihitung pada dataset pelatihan, dan melihat nilai **J** pada setiap iterasi dari **gradient descent**.\n",
    "\n",
    "#### Memplot Fungsi Biaya (Cost Function)\n",
    "Pada grafik, sumbu horizontal menunjukkan **jumlah iterasi** dari **gradient descent**, bukan nilai dari parameter seperti **w** atau **b**. Ini disebut **learning curve**. Setiap iterasi melibatkan pembaruan simultan dari parameter **w** dan **b**.\n",
    "\n",
    "Contohnya, jika kita memplot fungsi biaya **J** setelah **100 iterasi**, kita mendapatkan nilai **J** pada titik tertentu di sumbu vertikal yang menunjukkan biaya pada iterasi tersebut. Dengan memplot nilai **J** pada setiap iterasi, kita bisa melihat bagaimana **cost function** berubah selama proses pelatihan.\n",
    "\n",
    "#### Identifikasi Kurva Pembelajaran (Learning Curve)\n",
    "Grafik **learning curve** akan terlihat seperti ini:\n",
    "\n",
    "- **Sumbu horizontal**: Jumlah iterasi\n",
    "- **Sumbu vertikal**: Nilai dari **cost function J**\n",
    "\n",
    "Jika **gradient descent** berjalan dengan baik, nilai **J** akan **menurun** pada setiap iterasi. Jika **J** justru meningkat setelah satu iterasi, ada kemungkinan:\n",
    "\n",
    "- **Learning rate α** terlalu besar, atau\n",
    "- Ada bug dalam kode.\n",
    "\n",
    "#### Konvergensi\n",
    "Melihat kurva ini juga membantu kita mengetahui kapan **gradient descent** mulai konvergen. Misalnya, setelah 300 iterasi, kurva mungkin mulai **mendatar** yang menandakan bahwa **cost J** tidak menurun lagi dengan signifikan. Pada titik ini, kita dapat mengatakan bahwa **gradient descent** telah mencapai konvergensi.\n",
    "\n",
    "Namun, jumlah iterasi yang diperlukan untuk konvergensi bervariasi tergantung aplikasi. Pada satu aplikasi, mungkin hanya membutuhkan 30 iterasi, sementara yang lain bisa membutuhkan ribuan iterasi.\n",
    "\n",
    "#### Pengujian Konvergensi Otomatis\n",
    "Cara lain untuk mengukur konvergensi adalah dengan menggunakan **pengujian konvergensi otomatis**. Misalnya, dengan menggunakan nilai epsilon (𝜀) yang sangat kecil seperti 0.001 (atau 10^-3), kita dapat menetapkan bahwa jika penurunan **J** di bawah nilai epsilon, maka kita sudah berada di area datar kurva dan proses bisa dianggap selesai.\n",
    "\n",
    "Namun, saya biasanya lebih suka **melihat grafik** **learning curve** secara visual daripada hanya mengandalkan pengujian otomatis. Grafik sering memberikan gambaran yang lebih jelas apakah **gradient descent** berjalan dengan baik atau tidak.\n",
    "\n",
    "### Kesimpulan\n",
    "Dengan menggunakan **learning curve**, kita bisa memantau proses konvergensi **gradient descent**. Jika kurva mendatar dan **cost function** berhenti menurun, maka proses konvergensi sudah tercapai. Kita juga bisa menggunakan uji otomatis untuk menghentikan pelatihan ketika penurunan **J** tidak signifikan lagi.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
