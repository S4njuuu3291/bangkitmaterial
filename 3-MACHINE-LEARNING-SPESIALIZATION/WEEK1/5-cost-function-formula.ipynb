{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk menerapkan **regresi linear**, langkah pertama yang perlu dilakukan adalah mendefinisikan sesuatu yang disebut **fungsi biaya**. Fungsi ini akan kita bangun dalam video ini, dan fungsi biaya ini akan memberi tahu kita seberapa baik model yang kita miliki, agar kita bisa mencoba membuatnya lebih baik lagi. Mari kita lihat apa artinya.\n",
    "\n",
    "Ingat bahwa Anda memiliki **set pelatihan** yang berisi fitur input `x` dan target output `y`. Model yang akan Anda gunakan untuk memodelkan set pelatihan ini adalah fungsi linear:\n",
    "\n",
    "$$\n",
    "f_w, b(x) = w \\cdot x + b\n",
    "$$\n",
    "\n",
    "Untuk memperkenalkan sedikit lebih banyak terminologi, `w` dan `b` disebut **parameter model**. Dalam pembelajaran mesin, parameter model adalah variabel yang bisa Anda sesuaikan selama pelatihan untuk memperbaiki model. Kadang-kadang, Anda juga mendengar parameter `w` dan `b` disebut **koefisien** atau **bobot**.\n",
    "\n",
    "Sekarang mari kita lihat apa yang dilakukan parameter `w` dan `b`. Tergantung pada nilai yang Anda pilih untuk `w` dan `b`, Anda akan mendapatkan fungsi `f(x)` yang berbeda, yang menghasilkan garis yang berbeda pada grafik. Ingat bahwa kita bisa menulis `f(x)` sebagai singkatan dari `f_{w,b}(x)`. Kita akan melihat beberapa plot dari `f(x)` pada grafik. Mungkin Anda sudah familiar dengan menggambar garis pada grafik, tetapi meskipun ini mungkin sudah Anda ketahui, saya harap ini dapat membantu Anda membangun intuisi tentang bagaimana `w` dan `b` (parameter model) menentukan `f`.\n",
    "\n",
    "Contoh pertama: jika `w = 0` dan `b = 1.5`, maka `f(x)` tampak seperti garis horizontal. Dalam hal ini, fungsi `f(x)` adalah:\n",
    "\n",
    "$$\n",
    "f(x) = 0 \\cdot x + 1.5\n",
    "$$\n",
    "\n",
    "Jadi, `f` selalu bernilai konstan. Itu selalu memprediksi nilai `y = 1.5`. `y` yang diprediksi, atau `y hat`, selalu sama dengan `b`, dan di sini `b` juga disebut sebagai **intersep-y**, karena itu adalah tempat di mana fungsi tersebut memotong sumbu vertikal atau sumbu `y` pada grafik.\n",
    "\n",
    "Sebagai contoh kedua, jika `w = 0.5` dan `b = 0`, maka `f(x)` adalah:\n",
    "\n",
    "$$\n",
    "f(x) = 0.5 \\cdot x\n",
    "$$\n",
    "\n",
    "Ketika `x = 0`, prediksinya juga `0`, dan ketika `x = 2`, prediksinya adalah `0.5 \\cdot 2 = 1`. Anda akan mendapatkan garis seperti ini dan perhatikan bahwa kemiringannya adalah `0.5`. Nilai `w` memberi Anda **kemiringan** garis, yang di sini adalah `0.5`.\n",
    "\n",
    "Terakhir, jika `w = 0.5` dan `b = 1`, maka `f(x)` adalah:\n",
    "\n",
    "$$\n",
    "f(x) = 0.5 \\cdot x + 1\n",
    "$$\n",
    "\n",
    "Ketika `x = 0`, maka `f(x) = 1`, jadi garis ini memotong sumbu vertikal di `b = 1`. Juga, ketika `x = 2`, maka `f(x) = 2`. Jadi garis tersebut tampak seperti ini, dan kemiringannya tetap `0.5`.\n",
    "\n",
    "Ingat bahwa Anda memiliki set pelatihan seperti yang ditunjukkan di sini. Dengan **regresi linear**, apa yang ingin Anda lakukan adalah memilih nilai untuk parameter `w` dan `b` sehingga garis lurus yang dihasilkan oleh fungsi `f` dapat **memodelkan data dengan baik**. Seperti garis yang ditunjukkan di sini. Ketika saya melihat garis itu pas dengan data secara visual, Anda bisa menganggap ini berarti garis yang didefinisikan oleh `f` kira-kira melewati atau berada di dekat titik-titik dari set pelatihan, dibandingkan dengan garis-garis lain yang tidak begitu dekat dengan titik-titik tersebut.\n",
    "\n",
    "Sebagai pengingat beberapa notasi, contoh pelatihan seperti titik di sini didefinisikan oleh `x^i`, `y^i`, di mana `y` adalah target. Untuk input `x^i` tertentu, fungsi `f` juga membuat prediksi untuk `y`, yang hasilnya adalah `y hat^i` yang ditunjukkan di sini. Untuk pilihan model kita, `f(x^i)` adalah:\n",
    "\n",
    "$$\n",
    "f(x^i) = w \\cdot x^i + b\n",
    "$$\n",
    "\n",
    "Atau, bisa ditulis juga sebagai:\n",
    "\n",
    "$$\n",
    "\\hat{y}^i = f_{w,b}(x^i)\n",
    "$$\n",
    "\n",
    "Sekarang, pertanyaannya adalah bagaimana menemukan nilai `w` dan `b` sehingga prediksi `\\hat{y}^i` mendekati nilai target `y^i` untuk banyak atau mungkin semua contoh pelatihan `x^i, y^i`. Untuk menjawab itu, mari kita lihat bagaimana mengukur seberapa baik suatu garis **memodelkan data pelatihan**.\n",
    "\n",
    "Untuk itu, kita akan membangun **fungsi biaya**. Fungsi biaya ini membandingkan prediksi `\\hat{y}` dengan target `y` dengan cara mengukur selisihnya, yang disebut **error**.\n",
    "\n",
    "Langkah pertama adalah menghitung **error kuadrat** untuk setiap contoh pelatihan `i` di set pelatihan, seperti ini:\n",
    "\n",
    "$$\n",
    "\\text{Error} = \\hat{y}^i - y^i\n",
    "$$\n",
    "\n",
    "Kemudian kita **menghitung kuadrat dari error** tersebut. Lalu, kita ingin menghitung error ini untuk semua contoh pelatihan `i` dalam set pelatihan. Untuk itu, kita jumlahkan semua error kuadrat seperti ini:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{m} \\left( \\hat{y}^i - y^i \\right)^2\n",
    "$$\n",
    "\n",
    "Dengan `m` adalah jumlah contoh pelatihan. Jika Anda memiliki lebih banyak contoh pelatihan, maka `m` menjadi lebih besar dan fungsi biaya ini akan menghitung angka yang lebih besar. Ini adalah penjumlahan dari banyak contoh.\n",
    "\n",
    "Agar fungsi biaya ini tidak secara otomatis membesar seiring bertambahnya ukuran set pelatihan, secara konvensi, kita akan menghitung **rata-rata error kuadrat** daripada menjumlahkan error total. Kita lakukan ini dengan membagi jumlah total error kuadrat dengan `m`, seperti ini:\n",
    "\n",
    "$$\n",
    "\\frac{1}{m} \\sum_{i=1}^{m} \\left( \\hat{y}^i - y^i \\right)^2\n",
    "$$\n",
    "\n",
    "Akhirnya, kita ingin **membagi dengan 2m**, yang hanya bertujuan untuk membuat perhitungan kita nanti lebih rapi. Ini adalah fungsi biaya, yang sering disebut juga sebagai **fungsi biaya error kuadrat** atau **squared error cost function**, karena kita mengambil kuadrat dari perbedaan antara prediksi dan target.\n",
    "\n",
    "Fungsi biaya ini bekerja baik dalam banyak aplikasi untuk **regresi linear**, dan sebenarnya untuk banyak masalah regresi lainnya juga. Fungsi biaya ini sering digunakan karena memberikan hasil yang baik pada banyak aplikasi.\n",
    "\n",
    "Sebagai pengingat, prediksi `\\hat{y}` adalah output dari model `f(x)`. Kita dapat menulis ulang fungsi biaya `J(w, b)` sebagai:\n",
    "\n",
    "$$\n",
    "J(w, b) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( f(x^i) - y^i \\right)^2\n",
    "$$\n",
    "\n",
    "Akhirnya, kita ingin menemukan nilai `w` dan `b` yang meminimalkan fungsi biaya ini.\n",
    "\n",
    "Tetapi sebelum melanjutkan ke langkah itu, mari kita pahami lebih dalam lagi **apa yang sebenarnya dihitung oleh fungsi biaya**. Mungkin sekarang Anda berpikir bahwa kita sudah melakukan banyak **perhitungan matematika** hanya untuk mendefinisikan fungsi biaya ini. Tapi apa sebenarnya yang sedang dihitung? Mari kita lanjutkan ke video berikutnya di mana kita akan langkah demi langkah memahami **apa yang dimaksud dengan fungsi biaya**, dan semoga ini membantu Anda membangun intuisi mengenai arti dari nilai besar atau kecil pada `J(w, b)`.\n",
    "\n",
    "Mari kita lanjutkan ke video berikutnya.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
