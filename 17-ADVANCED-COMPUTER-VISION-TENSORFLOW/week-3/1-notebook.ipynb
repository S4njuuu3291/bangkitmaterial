{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Minggu ke-3: Pengenalan Segmentasi Gambar dengan TensorFlow**\n",
    "\n",
    "Selamat datang di minggu ke-3 kursus ini tentang *computer vision* dengan TensorFlow. Minggu ini, kita akan membahas segmentasi gambar, menjelajahi berbagai algoritma yang dapat digunakan untuk melakukan segmentasi pada gambar. Seperti biasa, kita akan langsung mempraktikkan kode-kode yang digunakan. Namun sebelum itu, mari kita tinjau kembali apa itu segmentasi gambar dan lihat sekilas algoritma-algoritma yang digunakan untuk mencapainya.\n",
    "\n",
    "### **Apa Itu Segmentasi Gambar?**\n",
    "Segmentasi gambar bertujuan untuk mengenali area dalam gambar dengan cara mengklasifikasikan setiap piksel ke dalam kelas tertentu. Piksel yang berada dalam kelas yang sama memiliki karakteristik yang serupa. Secara umum, segmentasi gambar dapat dibagi menjadi tiga tahap utama:\n",
    "1. **Menentukan Bentuk Objek**: Membedakan objek dalam gambar dengan menggambar garis luar objek. Hal ini dilakukan lebih detail dibandingkan dengan menggunakan *bounding box*.\n",
    "2. **Membagi Gambar Menjadi Segmen-segmen**: Setiap segmen akan dikaitkan dengan suatu objek.\n",
    "3. **Mengklasifikasikan Setiap Piksel**: Setiap piksel dalam gambar akan diklasifikasikan ke dalam kelas yang berbeda.\n",
    "\n",
    "### **Jenis-Jenis Segmentasi Gambar**\n",
    "Ada dua jenis segmentasi gambar:\n",
    "1. **Segmentasi Semantik**: Gambar dibagi menjadi berbagai kelas. Contohnya, dalam gambar terdapat orang dan meja yang masing-masing dikategorikan sebagai satu kelas.\n",
    "2. **Segmentasi Instance**: Setiap objek individual dalam kelas yang sama akan dipisahkan sebagai instance terpisah. Misalnya, jika ada dua meja dalam gambar, masing-masing meja akan dipisahkan sebagai instance yang berbeda.\n",
    "\n",
    "### **Contoh Peta Piksel**\n",
    "Peta piksel dapat digunakan untuk melatih model segmentasi gambar dengan memberi label pada piksel-piksel yang mewakili objek tertentu, seperti orang dan latar belakang.\n",
    "\n",
    "### **Arsitektur Model Segmentasi Gambar**\n",
    "Arsitektur umum untuk model segmentasi gambar adalah **encoder-decoder**. Proses kerjanya adalah sebagai berikut:\n",
    "1. **Encoder**: Mengambil gambar input dan mengekstrak fitur menggunakan *CNN* (Convolutional Neural Network). Encoder bertugas untuk mengolah gambar menjadi *feature map*.\n",
    "2. **Feature Map**: Menghasilkan fitur dari gambar, yang kemudian diproses melalui *downsampling*, yaitu proses mengurangi ukuran gambar namun tetap mempertahankan fitur utama, seperti garis atau objek dalam gambar.\n",
    "3. **Decoder**: Setelah gambar diproses oleh encoder, decoder bertugas untuk mengembalikan gambar ke ukuran aslinya dengan menambahkan detail yang hilang selama proses downsampling. Decoder juga menggunakan *CNN* dan memberikan label kelas pada setiap piksel yang dihasilkan.\n",
    "\n",
    "### **Hasil Akhir: Pixel Mask**\n",
    "Setelah melalui proses encoder-decoder, model akan menghasilkan **pixel mask**, di mana setiap piksel dalam gambar asli diberikan label kelas tertentu. Hal ini menghasilkan peta piksel yang memberi label pada setiap bagian gambar sesuai dengan kelas yang diidentifikasi.\n",
    "\n",
    "### **Kesimpulan**\n",
    "Segmentasi gambar dengan model encoder-decoder memungkinkan kita untuk memperoleh peta piksel yang dilabeli dengan kelas objek. Proses ini membantu dalam membedakan dan mengenali objek dalam gambar secara lebih detail dan akurat.\n",
    "\n",
    "---\n",
    "\n",
    "> **Catatan**: Arsitektur segmentasi gambar ini sangat bergantung pada pemilihan dan penggabungan lapisan-lapisan CNN untuk mengekstrak dan mengembalikan fitur-fitur penting dalam gambar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arsitektur Populer untuk Segmentasi Gambar\n",
    "\n",
    "Pada bagian ini, kita akan membahas beberapa arsitektur populer untuk segmentasi gambar. Kita akan mulai dengan **Fully Convolutional Networks (FCN)** seperti yang pertama kali diusulkan, kemudian membahas berbagai jaringan yang berbasis pada FCN, seperti **SegNet**, **U-Net**, **PSPNet**, dan **Mask R-CNN**. \n",
    "\n",
    "### 1. Fully Convolutional Networks (FCN)\n",
    "\n",
    "**Fully Convolutional Networks (FCN)** pertama kali diusulkan oleh Long, Shelhamer, dan Darrell dalam makalah mereka yang berjudul \"_Fully Convolutional Neural Networks for Semantic Segmentation_\". Tujuan mereka adalah untuk menggantikan lapisan **fully connected** pada CNN tradisional dengan lapisan konvolusional yang berfungsi sebagai **decoder**. \n",
    "\n",
    "- **Encoder** mendeteksi fitur dan mengurangi ukuran gambar.\n",
    "- **Decoder** meningkatkan ukuran gambar dan membuat peta segmentasi secara pixel-wise.\n",
    "\n",
    "Arsitektur FCN menggunakan lapisan konvolusional untuk mempelajari filter melalui inferensi maju dan **backpropagation**. Di akhir jaringan, ada lapisan prediksi **pixel-wise** yang menghasilkan peta segmentasi.\n",
    "\n",
    "#### Encoder pada FCN\n",
    "Encoder pada FCN berfungsi sebagai **feature extractor** yang mirip dengan lapisan ekstraksi fitur pada model **object detection**. Kita bisa menggunakan lapisan ekstraksi fitur dari model deteksi objek yang sudah dilatih sebelumnya, seperti **VGG16**, **ResNet 50**, atau **MobileNet**.\n",
    "\n",
    "#### Decoder pada FCN\n",
    "Decoder pada FCN biasanya disebut dengan **FCN-32**, **FCN-16**, atau **FCN-8**, dengan angka tersebut menunjukkan ukuran **stride** pada upsampling. Semakin kecil ukuran stride, semakin detail proses yang dilakukan. \n",
    "\n",
    "- **FCN-32**: Stride terbesar dan resolusi peta segmentasi terendah.\n",
    "- **FCN-16**: Stride lebih kecil dengan resolusi peta lebih tinggi.\n",
    "- **FCN-8**: Stride terkecil dengan resolusi peta paling mendekati **ground truth**.\n",
    "\n",
    "#### Implementasi FCN\n",
    "Kita akan membahas cara implementasi arsitektur ini lebih lanjut pada akhir minggu ini.\n",
    "\n",
    "### 2. SegNet\n",
    "\n",
    "**SegNet** adalah arsitektur lain yang populer untuk segmentasi gambar. SegNet sangat mirip dengan FCN, namun memiliki optimasi yang mencolok, yaitu lapisan encoder dan decoder yang simetris. Struktur ini berarti jumlah dan urutan lapisan pada encoder dan decoder sama. \n",
    "\n",
    "#### Contoh Arsitektur SegNet:\n",
    "- Encoder: Terdiri dari beberapa lapisan konvolusional yang diikuti dengan lapisan pooling.\n",
    "- Decoder: Mirror image dari encoder, dengan lapisan upsampling diikuti oleh lapisan konvolusional.\n",
    "\n",
    "### 3. U-Net\n",
    "\n",
    "**U-Net** adalah arsitektur yang juga sangat populer untuk segmentasi semantik. Sama seperti SegNet, U-Net memiliki struktur simetris antara upsampling dan downsampling. Nama **U-Net** berasal dari bentuk arsitektur yang menyerupai huruf \"U\". \n",
    "\n",
    "#### Karakteristik U-Net:\n",
    "- Terdiri dari beberapa tahap upsampling dan downsampling yang saling terkait.\n",
    "- Banyak digunakan dalam aplikasi medis untuk segmentasi gambar.\n",
    "\n",
    "### 4. Mask R-CNN\n",
    "\n",
    "**Mask R-CNN** adalah arsitektur populer untuk **instance segmentation**. Mask R-CNN dibangun berdasarkan **Faster R-CNN** yang digunakan dalam deteksi objek. Mask R-CNN menambahkan cabang tambahan setelah ekstraksi fitur dan Faster R-CNN untuk melakukan upsampling dan menghasilkan **pixel-wise segmentation masks**.\n",
    "\n",
    "Mask R-CNN mengubah model deteksi objek menjadi model segmentasi gambar.\n",
    "\n",
    "---\n",
    "\n",
    "### Kesimpulan\n",
    "\n",
    "Semua arsitektur ini—FCN, SegNet, U-Net, dan Mask R-CNN—memiliki pendekatan yang berbeda dalam menangani segmentasi gambar. Masing-masing memiliki kelebihan dan aplikasi yang berbeda, dan kita akan mengeksplorasi detail-detailnya lebih lanjut pada minggu ini.\n",
    "\n",
    "#### Selanjutnya:\n",
    "- Kita akan mulai dengan **Fully Convolutional Networks** yang akan dieksplorasi pada video berikutnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Networks (FCN) untuk Segmentasi Gambar\n",
    "\n",
    "## Pendahuluan\n",
    "Kita telah mempelajari segmentasi gambar, dan kini kita akan lebih mendalami model yang menjadi dasar semua model lainnya, yaitu **Fully Convolutional Neural Network (FCN)**.\n",
    "\n",
    "### Arsitektur FCN\n",
    "- **Encoder**: Menggunakan CNN sebagai ekstraktor fitur untuk mempelajari ciri-ciri penting dari gambar. Gambar diproses melalui lapisan konvolusional yang mengurangi ukuran gambar (downsample).\n",
    "- **Decoder**: Setelah gambar diproses oleh encoder, hasilnya diproses oleh decoder, yang menggunakan lapisan konvolusional tambahan untuk memperbesar gambar kembali ke ukuran semula (upsample), menghasilkan **masking pixelwise** yang digunakan untuk segmentasi gambar.\n",
    "\n",
    "### Model CNN yang Digunakan\n",
    "- Encoder dapat menggunakan lapisan konvolusional dari arsitektur CNN tradisional, seperti **VGG-16**, **ResNet-50**, dan **MobileNet**. \n",
    "- Lapisan yang tidak digunakan adalah **lapisan fully connected** dari model CNN tradisional, yang digunakan untuk klasifikasi dalam deteksi objek.\n",
    "\n",
    "### Dekoder Populer\n",
    "Beberapa decoder populer dalam FCN adalah:\n",
    "- **FCN-32**\n",
    "- **FCN-16**\n",
    "- **FCN-8**\n",
    "\n",
    "### FCN-32\n",
    "- Pada **FCN-32**, gambar diproses melalui lima lapisan pooling, yang mengurangi ukuran gambar hingga 32 kali lebih kecil.\n",
    "- Setelah itu, gambar di-**upsample** untuk mencapai ukuran asli dengan faktor 32, menghasilkan prediksi kelas pixelwise untuk gambar asli.\n",
    "\n",
    "### FCN-16\n",
    "- Pada **FCN-16**, selain menggunakan hasil pooling dari pool 5, juga memanfaatkan pool 4.\n",
    "- Output dari pool 5 di-**upsample** dua kali, dan hasil dari pool 4 digunakan untuk prediksi pixelwise.\n",
    "- Hasil prediksi ini kemudian digabungkan dan di-**upsample** dengan faktor 16, memberikan segmentasi gambar akhir.\n",
    "\n",
    "### FCN-8\n",
    "- **FCN-8** bekerja serupa dengan FCN-16, namun dengan dua kali upsampling setelah gabungan hasil dari pool 4 dan 5.\n",
    "- Kemudian, hasil ini di-**upsample** dengan faktor 8 untuk menghasilkan peta segmentasi akhir.\n",
    "\n",
    "### Perbandingan antara FCN-32, FCN-16, dan FCN-8\n",
    "- **FCN-8** menghasilkan segmentasi yang lebih tajam dan lebih baik dibandingkan **FCN-16** dan **FCN-32**, karena memanfaatkan hasil pooling sebelumnya dengan resolusi gambar yang lebih tinggi.\n",
    "- Namun, tergantung pada kebutuhan, **FCN-32** bisa cukup baik tanpa memerlukan proses ekstra yang ada pada FCN-16 atau FCN-8.\n",
    "\n",
    "## Kesimpulan\n",
    "- **FCN-32** adalah model dasar yang menghasilkan segmentasi dengan resolusi rendah, namun lebih cepat.\n",
    "- **FCN-16** dan **FCN-8** menawarkan hasil segmentasi yang lebih baik dengan pengorbanan waktu pemrosesan yang lebih lama.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Upsampling pada TensorFlow**\n",
    "\n",
    "Ada dua metode utama untuk melakukan upsampling dalam arsitektur model TensorFlow, yaitu menggunakan layer **UpSampling2D** dan **Transpose Convolution** (juga dikenal sebagai deconvolution). Berikut adalah penjelasan singkat tentang kedua metode tersebut.\n",
    "\n",
    "### 1. **UpSampling2D**\n",
    "\n",
    "Metode pertama adalah menggunakan **UpSampling2D**, yang merupakan API sederhana dan cepat untuk melakukan upsampling pada hasil pooling. Upsampling adalah proses memperbesar gambar dengan mengubahnya ke lebih banyak piksel.\n",
    "\n",
    "#### Jenis-Jenis Scaling\n",
    "\n",
    "Ada dua metode utama dalam scaling, yaitu:\n",
    "\n",
    "- **Nearest Scaling**: Menyalin piksel terdekat dari pool untuk piksel yang di-upscale.\n",
    "- **Bilinear Scaling**: Menggunakan interpolasi linear dari semua piksel terdekat untuk menghitung nilai rata-rata piksel yang baru.\n",
    "\n",
    "#### Parameter pada UpSampling2D\n",
    "\n",
    "- **Size**: Ukuran jendela upsampling. Misalnya, `(2, 2)` berarti setiap piksel di-upsample menjadi array 2x2 yang berisi empat piksel.\n",
    "- **Data Format**: Menentukan urutan dimensi data saat memuat gambar.\n",
    "  - **Channels First**: Dimensi channel ditulis sebelum dimensi tinggi dan lebar.\n",
    "  - **Channels Last**: Dimensi tinggi dan lebar ditulis sebelum dimensi channel.\n",
    "- **Interpolation Mode**: Menentukan bagaimana nilai piksel yang di-upsample dihitung.\n",
    "\n",
    "### 2. **Transpose Convolution (Deconvolution)**\n",
    "\n",
    "Metode kedua adalah **Transpose Convolution**, yang berfungsi untuk membalikkan proses **convolution**. Proses ini menggunakan nilai-nilai dalam filter untuk menentukan piksel yang akan menghasilkan nilai asli, dengan membalikkan operasi konvolusi.\n",
    "\n",
    "#### Penjelasan Proses\n",
    "\n",
    "- **Convolution**: Memproses nilai piksel dan tetangganya dengan filter untuk menghasilkan nilai piksel baru.\n",
    "- **Transpose Convolution**: Menggunakan filter untuk memperkirakan piksel yang menghasilkan nilai tersebut, tetapi karena hilangnya data (terutama di tepi gambar atau data yang hilang saat pooling), hasilnya tidak akan sempurna.\n",
    "\n",
    "#### Parameter pada Transpose Convolution\n",
    "\n",
    "- **Filters**: Jumlah filter yang digunakan dalam operasi.\n",
    "- **Kernel Size**: Ukuran filter, misalnya `(3, 3)` akan menghasilkan filter 3x3.\n",
    "\n",
    "---\n",
    "\n",
    "Dengan penjelasan ini, Anda dapat memahami kedua metode upsampling yang dapat diterapkan dalam TensorFlow. **UpSampling2D** memberikan solusi yang lebih sederhana, sementara **Transpose Convolution** memberikan hasil yang lebih mendekati konvolusi asli, meskipun ada kemungkinan kehilangan data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengantar Evaluasi Akurasi Segmentasi Citra\n",
    "\n",
    "Pada video sebelumnya, Anda melihat tentang **fully convolutional network** untuk segmentasi citra. Sekarang, kita akan melihat beberapa metrik yang digunakan untuk mengukur akurasi segmentasi. Segmentasi citra tidak seperti klasifikasi, di mana hanya ada benar atau salah. Anda harus melihat seluruh piksel dan menentukan mana yang diklasifikasikan dengan benar dan mana yang tidak. Ini sedikit lebih rumit. Dalam video ini, kita akan mempelajari beberapa metode untuk mengukur akurasi segmentasi.\n",
    "\n",
    "### Proses Pengujian pada Colab\n",
    "\n",
    "Saat Anda melalui Colab berikut, Anda akan melihat output seperti ini:\n",
    "- **Gambar asli di sebelah kiri**, dengan **segmen yang diprediksi dan segmen ground truth di sebelah kanan**.\n",
    "\n",
    "Ini adalah tes yang baik karena gambar tersebut gelap dan memiliki kontras rendah. Kita bisa melihat bahwa beberapa segmen yang diprediksi cukup baik, seperti **dinding**, **pohon**, dan **langit**, namun beberapa lainnya kurang baik, seperti **pejalan kaki**.\n",
    "\n",
    "### Konsep Utama dalam Segmentasi\n",
    "\n",
    "#### Area Tumpang Tindih (Overlap Area)\n",
    "Area tumpang tindih adalah jumlah prediksi **true positive**. Setiap piksel diklasifikasikan sebagai apakah itu **true positive** atau bukan. Jika piksel diklasifikasikan dengan benar, maka itu adalah **true positive**. Jumlah **true positive** ini memberikan area tumpang tindih.\n",
    "\n",
    "- **Intersection**: Menghitung semua piksel di mana kelas yang diprediksi dan kelas yang benar (ground truth) sama. Jika `y_pred` untuk sebuah piksel adalah kelas i dan `y_true` untuk piksel tersebut juga i, maka piksel itu dihitung sebagai **intersection**.\n",
    "  \n",
    "- **Combined Area**: Merupakan jumlah total piksel yang ada pada ground truth dan segmentasi yang diprediksi.\n",
    "\n",
    "- **Union Area**: Merupakan area gabungan yang dikurangi dengan area tumpang tindih.\n",
    "\n",
    "#### Intersection over Union (IoU)\n",
    "**IoU** adalah rasio antara **area tumpang tindih** dan **area gabungan**. Untuk setiap kelas, kita dapat menghitung intersection dan union, kemudian membagi keduanya untuk mendapatkan **IoU**. Di Colab, Anda akan melihat faktor pelurusan yang ditambahkan untuk mengurangi noise dalam perhitungan.\n",
    "\n",
    "#### Dice Score\n",
    "Dice score adalah dua kali **area tumpang tindih** dibagi dengan **area gabungan**. Dice score digunakan dalam situasi yang mirip dengan IoU dan keduanya sering digunakan bersama. Perbedaan halus antara keduanya adalah bahwa dice score cenderung menunjukkan kinerja rata-rata, sedangkan IoU membantu Anda memahami kinerja pada kasus terburuk.\n",
    "\n",
    "#### Perhitungan Class-wise\n",
    "Perhitungan untuk **IoU** dan **Dice Score** dilakukan dengan cara:\n",
    "1. Iterasi melalui kelas-kelas.\n",
    "2. Hitung **intersection** dan **combined area** untuk setiap kelas.\n",
    "3. Hitung skor berdasarkan formula masing-masing.\n",
    "\n",
    "### Hasil Evaluasi\n",
    "Dalam tes, kita melihat bahwa beberapa kelas seperti **langit**, **gedung**, **jalan**, dan **trotoar** diklasifikasikan dengan sangat baik. Namun, **lampu lalu lintas**, **tiang**, dan **pejalan kaki** menunjukkan hasil yang sangat buruk dengan nilai IoU yang sangat kecil. Ini menunjukkan bahwa model ini tidak cocok untuk digunakan di produksi.\n",
    "\n",
    "### Rangkuman dan Praktik Selanjutnya\n",
    "Pengenalan ini memberikan wawasan tentang bagaimana arsitektur **fully convolutional layers** digunakan dalam segmentasi citra. Sekarang, Anda akan mempraktikkan apa yang telah Anda pelajari dengan membangun model segmentasi citra untuk **segmen pandangan dashcam dalam tugas mobil otonom**. Anda akan menggunakan **VGG16** untuk encoder dan **FCN8** untuk decoder, serta menggunakan metrik **IoU** dan **Dice Score** untuk mengevaluasi kinerja model.\n",
    "\n",
    "Pada pelajaran berikutnya, kita akan beralih untuk melihat arsitektur **UNet** dalam segmentasi citra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **U-Net: Arsitektur Jaringan untuk Segmentasi Citra**\n",
    "\n",
    "U-Net adalah sebuah jaringan konvolusional sepenuhnya (Fully Convolutional Network - FCN) yang digunakan untuk segmentasi citra. Arsitektur ini memiliki perbedaan kunci dengan FCN lainnya, yaitu menggunakan **skip connections** antara encoder dan decoder.\n",
    "\n",
    "### **1. Pengantar**\n",
    "U-Net pertama kali diajukan dalam makalah **U-Net: Convolutional Networks for Biomedical Image Segmentation** pada tahun 2015 oleh Olaf Ronneberger, Philip Fischer, dan Thomas Brox. U-Net memperkenalkan konsep baru dalam segmentasi citra dengan penggunaan **skip connections** yang menghubungkan encoder dan decoder.\n",
    "\n",
    "#### **Ciri Khas U-Net**\n",
    "- **Skip Connections**: Menyambungkan lapisan encoder dan decoder, mengurangi kehilangan informasi saat pemrosesan citra.\n",
    "- **U Shape**: Arsitektur ini membentuk bentuk huruf \"U\" dengan bagian encoder di kiri dan decoder di kanan.\n",
    "\n",
    "### **2. Jalur Encoder**\n",
    "Pada sisi kiri U-Net, citra dimasukkan melalui lapisan konvolusional dan kemudian **down-sampled** menggunakan **max pooling**.\n",
    "\n",
    "- **Level 1**: Citra berukuran 128x128 diproses melalui dua lapisan konvolusi (64 filter) dan setelah pooling menjadi 64x64.\n",
    "- **Level 2**: Dilakukan konvolusi dengan 128 filter, kemudian pooling menjadi 32x32.\n",
    "- **Level 3**: Konvolusi dengan 256 filter dan pooling menjadi 16x16.\n",
    "- **Level 4**: Konvolusi dengan 512 filter dan pooling menjadi 8x8.\n",
    "\n",
    "### **3. Lapisan Bottleneck**\n",
    "Setelah citra melewati jalur encoder, data diteruskan ke lapisan **bottleneck** yang menggunakan lapisan konvolusi untuk mengekstraksi fitur lebih lanjut tanpa melalui pooling.\n",
    "\n",
    "### **4. Jalur Decoder**\n",
    "Pada sisi kanan U-Net, dimulai dengan **up-sampling** blok citra menjadi ukuran yang lebih besar (misalnya 8x8 menjadi 16x16).\n",
    "\n",
    "- **Level 5**: Dimulai dari 8x8 dan di-up-sample menjadi 16x16, diikuti dengan penggabungan filter encoder dan decoder.\n",
    "- **Level 4**: Citra di-up-sample menjadi 32x32 dan filter dari encoder dan decoder digabungkan.\n",
    "- **Level 3**: Citra di-up-sample menjadi 64x64, dan proses penggabungan filter diteruskan.\n",
    "- **Level 2**: Citra di-up-sample menjadi 128x128, penggabungan filter dilakukan lagi.\n",
    "  \n",
    "### **5. Output**\n",
    "Segmen citra akhir diperoleh dengan melakukan konvolusi 1x1 yang menghasilkan peta segmentasi dengan jumlah kelas yang sesuai. Sebagai contoh, jika model memprediksi 11 kelas, maka akan ada 11 filter konvolusi 1x1, masing-masing menghasilkan satu prediksi untuk setiap kelas.\n",
    "\n",
    "---\n",
    "\n",
    "Dengan menggunakan arsitektur seperti ini, U-Net dapat mencapai performa tinggi dalam tugas segmentasi citra, terutama pada citra medis, berkat penggunaan **skip connections** yang memelihara detail citra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
